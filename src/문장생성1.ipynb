{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    \"skt/kogpt2-base-v2\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전학습된 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    \"skt/kogpt2-base-v2\",\n",
    "    eos_token=\"</s>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그리디서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def getSearch(input_ids):\n",
    "    with torch.no_grad():\n",
    "      generated_ids = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,          # False 이면 컨텍스트가 동일하면 결과값이 항상 같으\n",
    "            min_length=0,\n",
    "            max_length=300,\n",
    "            no_repeat_ngram_size=3, # 토큰이 3개 이상 반복될 경우 3번째 토큰 확률을 0으로 \n",
    "            #repetition_penalty=1.5,\n",
    "            top_k=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "    return generated_ids  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  인코더, 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getEncoder(str):\n",
    "    return tokenizer.encode(str, return_tensors=\"pt\")\n",
    "\n",
    "def getDecoder(generated_ids):\n",
    "    return tokenizer.decode([el.item() for el in generated_ids[0]]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25906,  8702,  7801,  8084]])\n",
      "tensor([[25906,  8702,  7801,  8084,   406, 16563,   377,  6947,  7401,   387,\n",
      "         45887,   739,  7570, 11649,  9078,  7892,  9193,  6824,  8084,   406,\n",
      "          9050,  6969, 24117,  7281,  7480, 15842,  9265,  7162,   739,  7570,\n",
      "          9676, 22386,  9193,  6824, 25856, 16563,   377,  7965, 11597,   739,\n",
      "          7570, 13023, 44227, 42138,  8006, 25856, 16563,  8146,  8196,  7991,\n",
      "         28315, 14309,  9258, 25518, 35557,  7209,  9639, 13525,   377,  7965,\n",
      "          6969, 24117, 36625, 15842,  9265,  7470, 11382, 20111,   739,  7570,\n",
      "          9337,  9025,  9341,  8084,   406,   739,  7570,  9277, 10137, 34019,\n",
      "          6969,  8084,   406, 16518,  9873,  6824,  9277, 10578,  9098,  8239,\n",
      "          9025,  9846,  6969,  8084,   376, 16563,   377,  7098,   387,  9181,\n",
      "          6872, 16691, 16563,   377,  7970,  6872, 16691, 18519,   387,  9265,\n",
      "          7162,  9265,  7470,  9207, 45887,  9337,  9025,  9080, 10578,  9098,\n",
      "          7652,  6872, 16691,   377,  9258, 25518,  9265,  9248, 13525,  6947,\n",
      "          7312,  8143,  9022,  9862, 10423, 10377,  9294, 20694, 25793,  7235,\n",
      "         28801,  9138,  8277,  9505,   377,  8185,  7235,   739,  7570,  9098,\n",
      "          7652,  7801, 25856, 16563,  6947,  6824, 13701, 11271, 24508,  9775,\n",
      "          9258,  9427,  9036,  9515, 25518, 35557, 29416, 18952,  9427,  9036,\n",
      "         15726,  7426, 13525,   377,  6947,  7406, 10846,   739,  7570,  9078,\n",
      "          7892,  9122,  8046,  8084,   406,   377,  9258, 11271, 26307,   377,\n",
      "          8196,  6866,  9337,  9025,  9712, 14370, 32434,  9126, 16691, 16563,\n",
      "         27914,  9427,  9036,  7853,  8137, 12503,  9035,   377, 10072,  9337,\n",
      "          9025,  9846,  9031,  9239, 10578,  9098, 25856, 16563, 27914, 25518,\n",
      "         35557,  7321,  9639, 13525, 43056,  7162,  9427,  9036, 17148, 25518,\n",
      "         35557, 31845,  9526,  8271,  9021, 10816, 13707,   377,  6947,  7399,\n",
      "          7220,   739,  7570, 40259,  8084,   406, 17582,  9337,  9025, 12974,\n",
      "          9031,  9239, 41638,  9098, 25856,  9037,  6866,  9337, 12230, 14370,\n",
      "         32434, 10811, 25856, 16563, 28657, 31034,  9294, 15309, 15073,  9080,\n",
      "          9592,  9294, 24783, 26992,  8146,  9697,  6893,  7832,  6893, 10668,\n",
      "         12131,   377,  6947,  7084,  9037,  6866,  9135, 15084,  7801, 25856,\n",
      "           377,  9258,  9427, 25518, 35557, 19828,  9036,  9515,  9265,  9248]])\n",
      "안녕하세요?\"\n",
      "\"그럼, 제가 뭘 어떻게 하실 건가요? 아까 말씀드린 대로 저는 뭘 하고 싶은 건가요.\"\n",
      "\"아니, 뭘 해야 할지 모르겠어요.\"\n",
      "이제야 정신이 든 그는 고개를 끄덕이며 말했다.\n",
      "\"아까 말씀하신 대로 저를 위해서라면 뭘 할 수 있어요? 뭘 하는 게 좋을까요? 아니면 네가 하는 일을 해줄 수 있을까요!\"\n",
      "\"네, 알겠습니다.\"\n",
      "\"알겠습니다. 그럼, 저는 저를 위해 제가 할 수 있는 일을 해보겠습니다.\" 그는 고개를 저으며 말했다.\n",
      "그때의 그 모습과는 달리 그의 얼굴은 너무나도 밝고 반짝였다.\n",
      "\"저도 뭘 해보세요.\"\n",
      "그가 잠시 말을 멈추자, 그는 다시 한 번 고개를 끄덕이더니 다시 한 마디로 말했다.\n",
      "\"그렇다면 뭘 하실 거예요?\" 그는 말을 계속했다.\n",
      "\"제게 할 수 없는 일은 아무것도 없습니다.\"\n",
      "그는 다시 한숨을 쉬었다.\n",
      "\"제가 할 수 있을 것 같은 일을 해요.\"\n",
      "그는 고개를 끄떡이며 말했다.\n",
      "그리고는 다시 한 손으로 고개를 끄덕의 손짓으로 가리켰다.\n",
      "\"그런데 뭘 하려고요? 내가 할 수 없을 것 같은 일들을 해요. 제게 할 만한 일은 아무것도 없어요.\"\n",
      "그의 손이 그의 손을 잡고 있는 동안 그의 얼굴에 땀이 송골송골 맺혔다.\n",
      "\"그냥 제게 말해주세요.\" 그는 다시 고개를 끄덕을 한 번 저으며\n"
     ]
    }
   ],
   "source": [
    "encode = getEncoder(\"안녕하세요\")\n",
    "print(encode)\n",
    "\n",
    "search = getSearch(encode)\n",
    "print(search)\n",
    "\n",
    "decode = getDecoder(search)\n",
    "print(decode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
